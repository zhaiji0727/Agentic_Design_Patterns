{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FW3Eh5_OjUea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Language model initialized: gemini-2.5-flash\n",
      "\n",
      "--- üèÉ Running Agent with Query: 'What is the capital of France?' ---\n",
      "\n",
      "--- üèÉ Running Agent with Query: 'What's the weather like in London?' ---\n",
      "\n",
      "--- üèÉ Running Agent with Query: 'Tell me something about dogs.' ---\n",
      "\n",
      "--- üõ†Ô∏è Tool Called: search_information with query: 'weather in London' ---\n",
      "--- TOOL RESULT: The weather in London is currently cloudy with a temperature of 15¬∞C. ---\n",
      "\n",
      "--- üõ†Ô∏è Tool Called: search_information with query: 'dogs' ---\n",
      "--- TOOL RESULT: Simulated search result for 'dogs': No specific information found, but the topic seems interesting. ---\n",
      "\n",
      "--- üõ†Ô∏è Tool Called: search_information with query: 'capital of France' ---\n",
      "--- TOOL RESULT: The capital of France is Paris. ---\n",
      "\n",
      "--- ‚úÖ Final Agent Response ---\n",
      "The weather in London is currently cloudy with a temperature of 15¬∞C.\n",
      "\n",
      "--- ‚úÖ Final Agent Response ---\n",
      "The capital of France is Paris.\n",
      "\n",
      "--- ‚úÖ Final Agent Response ---\n",
      "It seems I couldn't find specific information about dogs using my current tools. Would you like me to try searching for something more specific about them? For example, \"what do dogs eat?\" or \"breeds of dogs.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, getpass\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from typing import List\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import logging\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import tool as langchain_tool\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# UNCOMMENT\n",
    "# Prompt the user securely and set API keys as an environment variables\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "try:\n",
    "   # A model with function/tool calling capabilities is required.\n",
    "   llm = ChatOpenAI(model=\"gemini-2.5-flash\", temperature=0, base_url=os.getenv(\"OPENAI_API_BASE\"), api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "   print(f\"‚úÖ Language model initialized: {llm.model_name}\")\n",
    "except Exception as e:\n",
    "   print(f\"üõë Error initializing language model: {e}\")\n",
    "   llm = None\n",
    "\n",
    "# --- Define a Tool ---\n",
    "@langchain_tool\n",
    "def search_information(query: str) -> str:\n",
    "   \"\"\"\n",
    "   Provides factual information on a given topic. Use this tool to find answers to phrases\n",
    "   like 'capital of France' or 'weather in London?'.\n",
    "   \"\"\"\n",
    "   print(f\"\\n--- üõ†Ô∏è Tool Called: search_information with query: '{query}' ---\")\n",
    "   # Simulate a search tool with a dictionary of predefined results.\n",
    "   simulated_results = {\n",
    "       \"weather in london\": \"The weather in London is currently cloudy with a temperature of 15¬∞C.\",\n",
    "       \"capital of france\": \"The capital of France is Paris.\",\n",
    "       \"population of earth\": \"The estimated population of Earth is around 8 billion people.\",\n",
    "       \"tallest mountain\": \"Mount Everest is the tallest mountain above sea level.\",\n",
    "       \"default\": f\"Simulated search result for '{query}': No specific information found, but the topic seems interesting.\"\n",
    "   }\n",
    "   result = simulated_results.get(query.lower(), simulated_results[\"default\"])\n",
    "   print(f\"--- TOOL RESULT: {result} ---\")\n",
    "   return result\n",
    "\n",
    "tools = [search_information]\n",
    "\n",
    "# --- Create a Tool-Calling Agent ---\n",
    "if llm:\n",
    "   # Create the agent using the new create_agent API\n",
    "   agent = create_agent(\n",
    "       model=llm,\n",
    "       tools=tools,\n",
    "       system_prompt=\"You are a helpful assistant.\"\n",
    "   )\n",
    "\n",
    "async def run_agent_with_tool(query: str):\n",
    "   \"\"\"Invokes the agent with a query and prints the final response.\"\"\"\n",
    "   print(f\"\\n--- üèÉ Running Agent with Query: '{query}' ---\")\n",
    "   try:\n",
    "       # The new agent expects a dictionary with 'messages'\n",
    "       response = await agent.ainvoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n",
    "       print(\"\\n--- ‚úÖ Final Agent Response ---\")\n",
    "       # The response contains the full state, we want the content of the last message\n",
    "       print(response[\"messages\"][-1].content)\n",
    "   except Exception as e:\n",
    "       print(f\"\\nüõë An error occurred during agent execution: {e}\")\n",
    "\n",
    "async def main():\n",
    "   \"\"\"Runs all agent queries concurrently.\"\"\"\n",
    "   tasks = [\n",
    "       run_agent_with_tool(\"What is the capital of France?\"),\n",
    "       run_agent_with_tool(\"What's the weather like in London?\"),\n",
    "       run_agent_with_tool(\"Tell me something about dogs.\") # Should trigger the default tool response\n",
    "   ]\n",
    "   await asyncio.gather(*tasks)\n",
    "\n",
    "nest_asyncio.apply()\n",
    "asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "apple-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
