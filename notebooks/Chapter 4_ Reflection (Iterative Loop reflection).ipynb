{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3NBB8hsfc7iJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================= REFLECTION LOOP: ITERATION 1 =========================\n",
      "\n",
      ">>> STAGE 1: GENERATING initial code...\n",
      "\n",
      "--- Generated Code (v1) ---\n",
      "```python\n",
      "def calculate_factorial(n: int) -> int:\n",
      "    \"\"\"\n",
      "    Calculates the factorial of a non-negative integer.\n",
      "\n",
      "    The factorial of a non-negative integer n, denoted by n!, is the product\n",
      "    of all positive integers less than or equal to n.\n",
      "    The factorial of 0 is defined as 1.\n",
      "\n",
      "    Args:\n",
      "        n (int): The non-negative integer for which to calculate the factorial.\n",
      "\n",
      "    Returns:\n",
      "        int: The factorial of n.\n",
      "\n",
      "    Raises:\n",
      "        TypeError: If the input n is not an integer.\n",
      "        ValueError: If n is a negative number.\n",
      "    \"\"\"\n",
      "    # 1. Handle invalid input: Check if n is an integer\n",
      "    if not isinstance(n, int):\n",
      "        raise TypeError(\"Input 'n' must be an integer.\")\n",
      "\n",
      "    # 2. Handle invalid input: Raise a ValueError if the input is a negative number\n",
      "    if n < 0:\n",
      "        raise ValueError(\"Factorial is not defined for negative numbers.\")\n",
      "\n",
      "    # 3. Handle edge case: The factorial of 0 is 1\n",
      "    if n == 0:\n",
      "        return 1\n",
      "\n",
      "    # 4. Calculate its factorial (n!) for positive integers\n",
      "    factorial_result = 1\n",
      "    for i in range(1, n + 1):\n",
      "        factorial_result *= i\n",
      "    return factorial_result\n",
      "\n",
      "```\n",
      "\n",
      ">>> STAGE 2: REFLECTING on the generated code...\n",
      "\n",
      "--- Critique ---\n",
      "No further critiques found. The code is satisfactory.\n",
      "\n",
      "============================== FINAL RESULT ==============================\n",
      "\n",
      "Final refined code after the reflection process:\n",
      "\n",
      "```python\n",
      "def calculate_factorial(n: int) -> int:\n",
      "    \"\"\"\n",
      "    Calculates the factorial of a non-negative integer.\n",
      "\n",
      "    The factorial of a non-negative integer n, denoted by n!, is the product\n",
      "    of all positive integers less than or equal to n.\n",
      "    The factorial of 0 is defined as 1.\n",
      "\n",
      "    Args:\n",
      "        n (int): The non-negative integer for which to calculate the factorial.\n",
      "\n",
      "    Returns:\n",
      "        int: The factorial of n.\n",
      "\n",
      "    Raises:\n",
      "        TypeError: If the input n is not an integer.\n",
      "        ValueError: If n is a negative number.\n",
      "    \"\"\"\n",
      "    # 1. Handle invalid input: Check if n is an integer\n",
      "    if not isinstance(n, int):\n",
      "        raise TypeError(\"Input 'n' must be an integer.\")\n",
      "\n",
      "    # 2. Handle invalid input: Raise a ValueError if the input is a negative number\n",
      "    if n < 0:\n",
      "        raise ValueError(\"Factorial is not defined for negative numbers.\")\n",
      "\n",
      "    # 3. Handle edge case: The factorial of 0 is 1\n",
      "    if n == 0:\n",
      "        return 1\n",
      "\n",
      "    # 4. Calculate its factorial (n!) for positive integers\n",
      "    factorial_result = 1\n",
      "    for i in range(1, n + 1):\n",
      "        factorial_result *= i\n",
      "    return factorial_result\n",
      "\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# --- Configuration ---\n",
    "# Load environment variables from .env file (for OPENAI_API_KEY)\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Check if the API key is set\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in .env file. Please add it.\")\n",
    "\n",
    "# Initialize the Chat LLM. We use a powerful model like gpt-4o for better reasoning.\n",
    "# A lower temperature is used for more deterministic and focused outputs.\n",
    "llm = ChatOpenAI(model=\"gemini-2.5-flash\", temperature=0.1, base_url=os.getenv(\"OPENAI_API_BASE\"), api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "\n",
    "def run_reflection_loop():\n",
    "    \"\"\"\n",
    "    Demonstrates a multi-step AI reflection loop to progressively improve a Python function.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- The Core Task ---\n",
    "    task_prompt = \"\"\"\n",
    "    Your task is to create a Python function named `calculate_factorial`.\n",
    "    This function should do the following:\n",
    "    1.  Accept a single integer `n` as input.\n",
    "    2.  Calculate its factorial (n!).\n",
    "    3.  Include a clear docstring explaining what the function does.\n",
    "    4.  Handle edge cases: The factorial of 0 is 1.\n",
    "    5.  Handle invalid input: Raise a ValueError if the input is a negative number.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- The Reflection Loop ---\n",
    "    max_iterations = 3\n",
    "    current_code = \"\"\n",
    "    # We will build a conversation history to provide context in each step.\n",
    "    message_history = [HumanMessage(content=task_prompt)]\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        print(\"\\n\" + \"=\"*25 + f\" REFLECTION LOOP: ITERATION {i + 1} \" + \"=\"*25)\n",
    "\n",
    "        # --- 1. GENERATE / REFINE STAGE ---\n",
    "        # In the first iteration, it generates. In subsequent iterations, it refines.\n",
    "        if i == 0:\n",
    "            print(\"\\n>>> STAGE 1: GENERATING initial code...\")\n",
    "            # The first message is just the task prompt.\n",
    "            response = llm.invoke(message_history)\n",
    "            current_code = response.content\n",
    "        else:\n",
    "            print(\"\\n>>> STAGE 1: REFINING code based on previous critique...\")\n",
    "            # The message history now contains the task, the last code, and the last critique.\n",
    "            # We instruct the model to apply the critiques.\n",
    "            message_history.append(HumanMessage(content=\"Please refine the code using the critiques provided.\"))\n",
    "            response = llm.invoke(message_history)\n",
    "            current_code = response.content\n",
    "\n",
    "        print(\"\\n--- Generated Code (v\" + str(i + 1) + \") ---\\n\" + current_code)\n",
    "        message_history.append(response) # Add the generated code to history\n",
    "\n",
    "        # --- 2. REFLECT STAGE ---\n",
    "        print(\"\\n>>> STAGE 2: REFLECTING on the generated code...\")\n",
    "\n",
    "        # Create a specific prompt for the reflector agent.\n",
    "        # This asks the model to act as a senior code reviewer.\n",
    "        reflector_prompt = [\n",
    "            SystemMessage(content=\"\"\"\n",
    "                You are a senior software engineer and an expert in Python.\n",
    "                Your role is to perform a meticulous code review.\n",
    "                Critically evaluate the provided Python code based on the original task requirements.\n",
    "                Look for bugs, style issues, missing edge cases, and areas for improvement.\n",
    "                If the code is perfect and meets all requirements, respond with the single phrase 'CODE_IS_PERFECT'.\n",
    "                Otherwise, provide a bulleted list of your critiques.\n",
    "            \"\"\"),\n",
    "            HumanMessage(content=f\"Original Task:\\n{task_prompt}\\n\\nCode to Review:\\n{current_code}\")\n",
    "        ]\n",
    "\n",
    "        critique_response = llm.invoke(reflector_prompt)\n",
    "        critique = critique_response.content\n",
    "\n",
    "        # --- 3. STOPPING CONDITION ---\n",
    "        if \"CODE_IS_PERFECT\" in critique:\n",
    "            print(\"\\n--- Critique ---\\nNo further critiques found. The code is satisfactory.\")\n",
    "            break\n",
    "\n",
    "        print(\"\\n--- Critique ---\\n\" + critique)\n",
    "        # Add the critique to the history for the next refinement loop.\n",
    "        message_history.append(HumanMessage(content=f\"Critique of the previous code:\\n{critique}\"))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*30 + \" FINAL RESULT \" + \"=\"*30)\n",
    "    print(\"\\nFinal refined code after the reflection process:\\n\")\n",
    "    print(current_code)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_reflection_loop()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1vt3Wx0n-4iJnkREJ3UFhwVYkh2yagpzh",
     "timestamp": 1750141768092
    }
   ]
  },
  "kernelspec": {
   "display_name": "apple-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
